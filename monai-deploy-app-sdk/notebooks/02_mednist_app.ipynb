{"cells":[{"cell_type":"markdown","metadata":{"id":"rKtDTLYzPSBe"},"source":["# MONAI Deploy App SDKを使ったMedNIST分類器アプリのデプロイメント\n","\n","このチュートリアルでは、MONAI Deploy App SDKを使って学習したモデルを、推論を行うローカルプログラム、同じことを行うワークフロージョブ、Dockerコンテナによるワークフロー実行として実行可能な成果物にパッケージングするプロセスをデモしています。\n","\n","このチュートリアルでは、[こちらのMONAIチュートリアル](https://github.com/Project-MONAI/tutorials/blob/master/2d_classification/mednist_tutorial.ipynb)のようにMedNIST分類器を学習させ、推論アプリケーションを実装＆パッケージ化し、ローカルでアプリケーションを実行することになります。\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hx8ujdoUPSBk"},"source":["## MONAI Coreを用いたMedNIST分類器モデルの学習"]},{"cell_type":"markdown","metadata":{"id":"Iku5900YPSBl"},"source":["### 環境のセットアップ"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K9JqH2vWPSBm"},"outputs":[],"source":["# Install necessary packages for MONAI Core\n","!python -c \"import monai\" || pip install -q \"monai[pillow, tqdm]\"\n","!python -c \"import ignite\" || pip install -q \"monai[ignite]\"\n","!python -c \"import gdown\" || pip install -q \"monai[gdown]\"\n","\n","# Install MONAI Deploy App SDK package\n","!python -c \"import monai.deploy\" || pip install -q \"monai-deploy-app-sdk\""]},{"cell_type":"markdown","metadata":{"id":"MvxzbxrOPSBn"},"source":["### importsのセットアップ"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"A4J_B26ePSBn","outputId":"81511cdd-74e7-4733-f664-3547e2746296"},"outputs":[{"name":"stdout","output_type":"stream","text":["MONAI version: 0.6.0\n","Numpy version: 1.19.5\n","Pytorch version: 1.9.0\n","MONAI flags: HAS_EXT = False, USE_COMPILED = False\n","MONAI rev id: 0ad9e73639e30f4f1af5a1f4a45da9cb09930179\n","\n","Optional dependencies:\n","Pytorch Ignite version: 0.4.5\n","Nibabel version: 3.2.1\n","scikit-image version: 0.17.2\n","Pillow version: 8.3.1\n","Tensorboard version: 2.6.0\n","gdown version: 3.13.0\n","TorchVision version: 0.10.0\n","ITK version: 5.2.0\n","tqdm version: 4.62.1\n","lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n","psutil version: 5.8.0\n","pandas version: 1.1.5\n","einops version: 0.3.2\n","\n","For details about installing the optional dependencies, please visit:\n","    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n","\n"]}],"source":["# Copyright 2020 MONAI Consortium\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\n","import os\n","import shutil\n","import tempfile\n","import glob\n","import PIL.Image\n","import torch\n","import numpy as np\n","\n","from ignite.engine import Events\n","\n","from monai.apps import download_and_extract\n","from monai.config import print_config\n","from monai.networks.nets import DenseNet121\n","from monai.engines import SupervisedTrainer\n","from monai.transforms import (\n","    AddChannel,\n","    Compose,\n","    LoadImage,\n","    RandFlip,\n","    RandRotate,\n","    RandZoom,\n","    ScaleIntensity,\n","    EnsureType,\n",")\n","from monai.utils import set_determinism\n","\n","set_determinism(seed=0)\n","\n","print_config()"]},{"cell_type":"markdown","metadata":{"id":"qdBazghJPSBp"},"source":["### データセットのダウンロード\n","\n","MedNISTのデータセットは、[TCIA](https://wiki.cancerimagingarchive.net/display/Public/Data+Usage+Policies+and+Restrictions)、RSNA Bone Age Challenge(https://www.rsna.org/education/ai-resources-and-training/ai-image-challenge/rsna-pediatric-bone-age-challenge-2017),  [the NIH Chest X-ray dataset](https://cloud.google.com/healthcare/docs/resources/public-datasets/nih-chest)の複数のセットから収集されたものです。\n","\n","このデータセットは、[Dr. Bradley J. Erickson M.D., Ph.D.](https://www.mayo.edu/research/labs/radiology-informatics/overview) (Department of Radiology, Mayo Clinic)により、クリエイティブ・コモンズ CC BY-SA 4.0 ライセンスの下で提供されているものである。\n","\n","MedNISTデータセットを使用する場合は、出典を明記してください。"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"iIkGn7FVPSBq","outputId":"ecf04868-1073-415f-bb4f-efabf5f50265"},"outputs":[{"name":"stdout","output_type":"stream","text":["/tmp/tmpgh08b1ks\n"]},{"name":"stderr","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1QsnnkvZyJPcbRoV_ArW8SnE1OTuoVbKE\n","To: /tmp/tmpthbz6o8r/MedNIST.tar.gz\n","61.8MB [00:05, 10.7MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Downloaded: /tmp/tmpgh08b1ks/MedNIST.tar.gz\n","Verified 'MedNIST.tar.gz', md5: 0bc7306e7427e00ad1c5526a6677552d.\n","Writing into directory: /tmp/tmpgh08b1ks.\n"]}],"source":["directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n","root_dir = tempfile.mkdtemp() if directory is None else directory\n","print(root_dir)\n","\n","resource = \"https://drive.google.com/uc?id=1QsnnkvZyJPcbRoV_ArW8SnE1OTuoVbKE\"\n","md5 = \"0bc7306e7427e00ad1c5526a6677552d\"\n","\n","compressed_file = os.path.join(root_dir, \"MedNIST.tar.gz\")\n","data_dir = os.path.join(root_dir, \"MedNIST\")\n","if not os.path.exists(data_dir):\n","    download_and_extract(resource, compressed_file, root_dir, md5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kI2Q-aYqPSBr","outputId":"5217b017-319d-4be0-fd5e-fd9f2c0711f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Label names: ['AbdomenCT', 'BreastMRI', 'CXR', 'ChestCT', 'Hand', 'HeadCT']\n","Label counts: [10000, 8954, 10000, 10000, 10000, 10000]\n","Total image count: 58954\n","Image dimensions: 64 x 64\n"]}],"source":["subdirs = sorted(glob.glob(f\"{data_dir}/*/\"))\n","\n","class_names = [os.path.basename(sd[:-1]) for sd in subdirs]\n","image_files = [glob.glob(f\"{sb}/*\") for sb in subdirs]\n","\n","image_files_list = sum(image_files, [])\n","image_class = sum(([i] * len(f) for i, f in enumerate(image_files)), [])\n","image_width, image_height = PIL.Image.open(image_files_list[0]).size\n","\n","print(f\"Label names: {class_names}\")\n","print(f\"Label counts: {list(map(len, image_files))}\")\n","print(f\"Total image count: {len(image_class)}\")\n","print(f\"Image dimensions: {image_width} x {image_height}\")"]},{"cell_type":"markdown","metadata":{"id":"Uj3ODPI5PSBs"},"source":["### セットアップと学習\n","\n","ここでは、transformシーケンスを作成し、ネットワークを学習させる。検証やテストは、実際に機能することが分かっており、ここでは必要ないので省略する。\n","\n","\n","(train_transforms)="]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7dhXv5d7PSBu"},"outputs":[],"source":["train_transforms = Compose(\n","    [\n","        LoadImage(image_only=True),\n","        AddChannel(),\n","        ScaleIntensity(),\n","        RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n","        RandFlip(spatial_axis=0, prob=0.5),\n","        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n","        EnsureType(),\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BMoO4wyOPSBu"},"outputs":[],"source":["class MedNISTDataset(torch.utils.data.Dataset):\n","    def __init__(self, image_files, labels, transforms):\n","        self.image_files = image_files\n","        self.labels = labels\n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return len(self.image_files)\n","\n","    def __getitem__(self, index):\n","        return self.transforms(self.image_files[index]), self.labels[index]\n","\n","\n","# データセットとローダーが1つであれば、検証やテストは必要ありません。\n","train_ds = MedNISTDataset(image_files_list, image_class, train_transforms)\n","train_loader = torch.utils.data.DataLoader(train_ds, batch_size=300, shuffle=True, num_workers=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ja8EZPVPPSBv"},"outputs":[],"source":["device = torch.device(\"cuda:0\")\n","net = DenseNet121(spatial_dims=2, in_channels=1, out_channels=len(class_names)).to(device)\n","loss_function = torch.nn.CrossEntropyLoss()\n","opt = torch.optim.Adam(net.parameters(), 1e-5)\n","max_epochs = 5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7E0yytvZPSBw","outputId":"16f1b809-215a-4df1-b261-82460b1ccc16"},"outputs":[{"name":"stderr","output_type":"stream","text":["Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448272031/work/c10/core/TensorImpl.h:1156.)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/5 Loss: 0.1811893731355667\n","Epoch 2/5 Loss: 0.08026652783155441\n","Epoch 3/5 Loss: 0.05008228123188019\n","Epoch 4/5 Loss: 0.01724996417760849\n","Epoch 5/5 Loss: 0.029151903465390205\n"]}],"source":["def _prepare_batch(batch, device, non_blocking):\n","    return tuple(b.to(device) for b in batch)\n","\n","\n","trainer = SupervisedTrainer(device, max_epochs, train_loader, net, opt, loss_function, prepare_batch=_prepare_batch)\n","\n","\n","@trainer.on(Events.EPOCH_COMPLETED)\n","def _print_loss(engine):\n","    print(f\"Epoch {engine.state.epoch}/{engine.state.max_epochs} Loss: {engine.state.output[0]['loss']}\")\n","\n","\n","trainer.run()"]},{"cell_type":"markdown","metadata":{"id":"nVjmafoGPSBw"},"source":["ネットワークは`classifier.zip`という名前のTorchscriptオブジェクトとしてここに保存されます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jZiY4s3EPSBw"},"outputs":[],"source":["torch.jit.script(net).save(\"classifier.zip\")"]},{"cell_type":"markdown","metadata":{"id":"9GCze5yiPSBx"},"source":["## MONAI Deploy App SDKによるアプリケーションの実装とパッケージング\n","\n","Torchscriptのモデル(`classifier.zip`)をもとに、入力されたJpeg画像を処理し、予測（分類）結果をJSONファイル(`output.json`)として書き出すアプリケーションを実装します。\n","\n","\n","### プリケーションクラスでの演算子の作成と接続\n","\n","学習時の事前変換として、以下の train transformsを使用しました。\n","\n","\n","```{code-block} python\n","---\n","lineno-start: 1\n","emphasize-lines: 3,4,5,9\n","caption: |\n","    Train transforms used in training\n","---\n","train_transforms = Compose(\n","    [\n","        LoadImage(image_only=True),\n","        AddChannel(),\n","        ScaleIntensity(),\n","        RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n","        RandFlip(spatial_axis=0, prob=0.5),\n","        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n","        EnsureType(),\n","    ]\n",")\n","```\n","\n","`RandRotate`, `RandFlip`, `RandZoom` 変換は学習時にのみ使用され、推論時には不要である。\n","\n","推論アプリケーションでは、2つのオペレータを定義します。\n","\n","1. `LoadPILOperator` - 入力パスからJPEG画像をロードし、ロードされた画像オブジェクトを次のオペレータに渡します。\n","    - このオペレータは、*train_transforms* の `LoadImage(image_only=True)` と同様の働きをしますが、扱う画像は1枚だけです。\n","    - **Input**: ファイルパス ([`DataPath`](https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/modules/_autosummary/monai.deploy.core.domain.DataPath.html))\n","    - **Output**: メモリ上の画像オブジェクト ([`Image`](https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/modules/_autosummary/monai.deploy.core.domain.Image.html))\n","2. `MedNISTClassifierOperator` -  与えられた画像をMONAIの`Compose`クラスで前変換し、Torchscriptのモデル（`classifier.zip`)に送り、予測結果をJSONファイル(`output.json`)に書き出す。\n","    - プリトランスフォームは、3つのトランスフォームで構成されています。 -- `AddChannel`, `ScaleIntensity`, `EnsureType`.\n","    - **Input**: メモリ上の画像オブジェクト ([`Image`](https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/modules/_autosummary/monai.deploy.core.domain.Image.html))\n","    - **Output**: 予測結果(`output.json`)が書き込まれるフォルダパス([`DataPath`](https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/modules/_autosummary/monai.deploy.core.domain.DataPath.html))\n","\n","アプリケーションのワークフローは以下のようになる。\n","\n","```{mermaid}\n","%%{init: {\"theme\": \"base\", \"themeVariables\": { \"fontSize\": \"16px\"}} }%%\n","\n","classDiagram\n","    direction LR\n","\n","    LoadPILOperator --|> MedNISTClassifierOperator : image...image\n","\n","\n","    class LoadPILOperator {\n","        <in>image : DISK\n","        image(out) IN_MEMORY\n","    }\n","    class MedNISTClassifierOperator {\n","        <in>image : IN_MEMORY\n","        output(out) DISK\n","    }\n","```\n","\n","\n","#### インポートのセットアップ\n","\n","必要なクラスやデコレーターをインポートして、`MEDNIST_CLASSES` を定義しましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u4a1mwq1PSBy"},"outputs":[],"source":["import monai.deploy.core as md  # 'md' stands for MONAI Deploy (or can use 'core' instead)\n","from monai.deploy.core import (\n","    Application,\n","    DataPath,\n","    ExecutionContext,\n","    Image,\n","    InputContext,\n","    IOType,\n","    Operator,\n","    OutputContext,\n",")\n","from monai.transforms import AddChannel, Compose, EnsureType, ScaleIntensity\n","\n","MEDNIST_CLASSES = [\"AbdomenCT\", \"BreastMRI\", \"CXR\", \"ChestCT\", \"Hand\", \"HeadCT\"]"]},{"cell_type":"markdown","metadata":{"id":"NyDOzx3KPSBy"},"source":["#### Operatorクラスの作成\n","\n","\n","##### LoadPILOperator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J1e-E7rzPSBy"},"outputs":[],"source":["@md.input(\"image\", DataPath, IOType.DISK)\n","@md.output(\"image\", Image, IOType.IN_MEMORY)\n","@md.env(pip_packages=[\"pillow\"])\n","class LoadPILOperator(Operator):\n","    \"\"\"与えられた入力（DataPath）から画像を読み込み、出力（Image）にnumpy配列を設定します。\"\"\"\n","\n","    def compute(self, op_input: InputContext, op_output: OutputContext, context: ExecutionContext):\n","        import numpy as np\n","        from PIL import Image as PILImage\n","\n","        input_path = op_input.get().path\n","        if input_path.is_dir():\n","            input_path = next(input_path.glob(\"*.*\"))  # 最初のファイルを取る\n","\n","        image = PILImage.open(input_path)\n","        image = image.convert(\"L\")  # グレースケール画像に変換する\n","        image_arr = np.asarray(image)\n","\n","        output_image = Image(image_arr)  # numpyの配列でImage domainオブジェクトを生成します。\n","        op_output.set(output_image)"]},{"cell_type":"markdown","metadata":{"id":"qFpxAJJTPSBz"},"source":["##### MedNISTClassifierOperator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BKtnHB1APSBz"},"outputs":[],"source":["@md.input(\"image\", Image, IOType.IN_MEMORY)\n","@md.output(\"output\", DataPath, IOType.DISK)\n","@md.env(pip_packages=[\"monai\"])\n","class MedNISTClassifierOperator(Operator):\n","    \"\"\"与えられた画像を分類し、クラス名を返す。\"\"\"\n","\n","    @property\n","    def transform(self):\n","        return Compose([AddChannel(), ScaleIntensity(), EnsureType()])\n","\n","    def compute(self, op_input: InputContext, op_output: OutputContext, context: ExecutionContext):\n","        import json\n","\n","        import torch\n","\n","        img = op_input.get().asnumpy()  # (64, 64), uint8\n","        image_tensor = self.transform(img)  # (1, 64, 64), torch.float64\n","        image_tensor = image_tensor[None].float()  # (1, 1, 64, 64), torch.float32\n","\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        image_tensor = image_tensor.to(device)\n","\n","        model = context.models.get()  # TorchScriptModel オブジェクトを取得します。\n","\n","        with torch.no_grad():\n","            outputs = model(image_tensor)\n","\n","        _, output_classes = outputs.max(dim=1)\n","\n","        result = MEDNIST_CLASSES[output_classes[0]]  # クラス名を取得する\n","        print(result)\n","\n","        # 出力（フォルダ）パスを取得し、存在しない場合はフォルダを作成する。\n","        output_folder = op_output.get().path\n","        output_folder.mkdir(parents=True, exist_ok=True)\n","\n","        # 結果を \"output.json \"に書き込む\n","        output_path = output_folder / \"output.json\"\n","        with open(output_path, \"w\") as fp:\n","            json.dump(result, fp)"]},{"cell_type":"markdown","metadata":{"id":"StdNEEUCPSB0"},"source":["#### アプリケーションクラスの作成\n","\n","アプリケーションクラスは以下のようなものです。\n","\n","`Application` クラスを継承した `App` クラスを定義する。\n","\n","`loadPILOperator` と `MedNISTClassifierOperator` は `App` の `compose()` メソッドの `self.add_flow()` で接続される。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QUykjurSPSB0"},"outputs":[],"source":["@md.resource(cpu=1, gpu=1, memory=\"1Gi\")\n","class App(Application):\n","    \"\"\"MedNIST分類器のアプリケーションクラス。\"\"\"\n","\n","    def compose(self):\n","        load_pil_op = LoadPILOperator()\n","        classifier_op = MedNISTClassifierOperator()\n","\n","        self.add_flow(load_pil_op, classifier_op)"]},{"cell_type":"markdown","metadata":{"id":"MJ6tC_ruPSB0"},"source":["### アプリをローカルで実行する\n","\n","テスト用の入力ファイルのパスを探してみましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"np8-dJEAPSB1","outputId":"7afb6a71-b696-4024-d678-da8197191beb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test input file path: /tmp/tmpgh08b1ks/MedNIST/AbdomenCT/007000.jpeg\n"]}],"source":["test_input_path = image_files[0][0]\n","print(f\"Test input file path: {test_input_path}\")"]},{"cell_type":"markdown","metadata":{"id":"qN92kvYdPSB1"},"source":["Jupyterノートブックでアプリを実行することができます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_jXuylhePSB1"},"outputs":[],"source":["app = App()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ONWHZuWPSB1","outputId":"afc25596-5535-4c28-b6f1-5e8e1406b2bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34mGoing to initiate execution of operator LoadPILOperator\u001b[39m\n","\u001b[32mExecuting operator LoadPILOperator \u001b[33m(Process ID: 14835, Operator ID: dd5dee72-9764-458a-9719-dc89f3cd14ea)\u001b[39m\n","\u001b[34mDone performing execution of operator LoadPILOperator\n","\u001b[39m\n","\u001b[34mGoing to initiate execution of operator MedNISTClassifierOperator\u001b[39m\n","\u001b[32mExecuting operator MedNISTClassifierOperator \u001b[33m(Process ID: 14835, Operator ID: 9b032f84-6a73-4f59-9c56-d04efed5bdb5)\u001b[39m\n","AbdomenCT\n","\u001b[34mDone performing execution of operator MedNISTClassifierOperator\n","\u001b[39m\n"]}],"source":["app.run(input=test_input_path, output=\"output\", model=\"classifier.zip\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ZbkmBeaPSB2","outputId":"29cfc838-9c17-4d43-a23d-cec95f2721cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["\"AbdomenCT\""]}],"source":["!cat output/output.json"]},{"cell_type":"markdown","metadata":{"id":"bTkgSeZ6PSB2"},"source":["Jupyter notebook内でアプリケーションを検証したら、上記のコードを連結して、アプリケーション全体をファイル(`mednist_classifier_monaideploy.py`)として書き出し、以下の行を追加します。\n","\n","```python\n","if __name__ == \"__main__\":\n","    App(do_run=True)\n","```\n","\n","上記の行は `python` インタープリタを使ってアプリケーションコードを実行するために必要なものです。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-aGkALwgPSB2","executionInfo":{"status":"ok","timestamp":1665479364287,"user_tz":-540,"elapsed":9,"user":{"displayName":"ryo sanada","userId":"00608017676273255028"}},"outputId":"019a1bd9-111e-4e34-8bfe-c61a727d8963"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing mednist_classifier_monaideploy.py\n"]}],"source":["%%writefile mednist_classifier_monaideploy.py\n","\n","# Copyright 2021 MONAI Consortium\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\n","import monai.deploy.core as md  # 'md' stands for MONAI Deploy (or can use 'core' instead)\n","from monai.deploy.core import (\n","    Application,\n","    DataPath,\n","    ExecutionContext,\n","    Image,\n","    InputContext,\n","    IOType,\n","    Operator,\n","    OutputContext,\n",")\n","from monai.transforms import AddChannel, Compose, EnsureType, ScaleIntensity\n","\n","MEDNIST_CLASSES = [\"AbdomenCT\", \"BreastMRI\", \"CXR\", \"ChestCT\", \"Hand\", \"HeadCT\"]\n","\n","\n","@md.input(\"image\", DataPath, IOType.DISK)\n","@md.output(\"image\", Image, IOType.IN_MEMORY)\n","@md.env(pip_packages=[\"pillow\"])\n","class LoadPILOperator(Operator):\n","    \"\"\"与えられた入力（DataPath）から画像を読み込み、出力（Image）にnumpy配列を設定します。\"\"\"\n","\n","    def compute(self, op_input: InputContext, op_output: OutputContext, context: ExecutionContext):\n","        import numpy as np\n","        from PIL import Image as PILImage\n","\n","        input_path = op_input.get().path\n","        if input_path.is_dir():\n","            input_path = next(input_path.glob(\"*.*\"))  # 最初のファイルを取る\n","\n","        image = PILImage.open(input_path)\n","        image = image.convert(\"L\")  # グレースケール画像に変換する\n","        image_arr = np.asarray(image)\n","\n","        output_image = Image(image_arr)  # numpyの配列でImage domainオブジェクトを生成します。\n","        op_output.set(output_image)\n","\n","\n","@md.input(\"image\", Image, IOType.IN_MEMORY)\n","@md.output(\"output\", DataPath, IOType.DISK)\n","@md.env(pip_packages=[\"monai\"])\n","class MedNISTClassifierOperator(Operator):\n","    \"\"\"与えられた画像を分類し、クラス名を返す。\"\"\"\n","\n","    @property\n","    def transform(self):\n","        return Compose([AddChannel(), ScaleIntensity(), EnsureType()])\n","\n","    def compute(self, op_input: InputContext, op_output: OutputContext, context: ExecutionContext):\n","        import json\n","\n","        import torch\n","\n","        img = op_input.get().asnumpy()  # (64, 64), uint8\n","        image_tensor = self.transform(img)  # (1, 64, 64), torch.float64\n","        image_tensor = image_tensor[None].float()  # (1, 1, 64, 64), torch.float32\n","\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        image_tensor = image_tensor.to(device)\n","\n","        model = context.models.get()  # TorchScriptModel オブジェクトを取得します。\n","\n","        with torch.no_grad():\n","            outputs = model(image_tensor)\n","\n","        _, output_classes = outputs.max(dim=1)\n","\n","        result = MEDNIST_CLASSES[output_classes[0]]  # クラス名を取得する\n","        print(result)\n","\n","        # 出力（フォルダ）パスを取得し、存在しない場合はフォルダを作成する。\n","        output_folder = op_output.get().path\n","        output_folder.mkdir(parents=True, exist_ok=True)\n","\n","        # 結果を \"output.json \"に書き込む\n","        output_path = output_folder / \"output.json\"\n","        with open(output_path, \"w\") as fp:\n","            json.dump(result, fp)\n","\n","\n","@md.resource(cpu=1, gpu=1, memory=\"1Gi\")\n","class App(Application):\n","    \"\"\"MedNIST分類器のアプリケーションクラス。\"\"\"\n","\n","    def compose(self):\n","        load_pil_op = LoadPILOperator()\n","        classifier_op = MedNISTClassifierOperator()\n","\n","        self.add_flow(load_pil_op, classifier_op)\n","\n","\n","if __name__ == \"__main__\":\n","    App(do_run=True)"]},{"cell_type":"markdown","metadata":{"id":"pZ9q249gPSB3"},"source":["今回は、コマンドラインでアプリを実行してみましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CFd0X_1jPSB3","outputId":"9d312209-64d5-4231-eeb5-219b7e3104e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34mGoing to initiate execution of operator LoadPILOperator\u001b[39m\n","\u001b[32mExecuting operator LoadPILOperator \u001b[33m(Process ID: 18193, Operator ID: de9a33aa-0abb-4e64-88af-90b27617ff63)\u001b[39m\n","\u001b[34mDone performing execution of operator LoadPILOperator\n","\u001b[39m\n","\u001b[34mGoing to initiate execution of operator MedNISTClassifierOperator\u001b[39m\n","\u001b[32mExecuting operator MedNISTClassifierOperator \u001b[33m(Process ID: 18193, Operator ID: 73bfa497-459c-4ef3-998a-8d162be57687)\u001b[39m\n","Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448272031/work/c10/core/TensorImpl.h:1156.)\n","AbdomenCT\n","\u001b[34mDone performing execution of operator MedNISTClassifierOperator\n","\u001b[39m\n"]}],"source":["!python mednist_classifier_monaideploy.py -i {test_input_path} -o output -m classifier.zip"]},{"cell_type":"markdown","metadata":{"id":"IAlWKzoxPSB3"},"source":["上記のコマンドは、以下のコマンドラインと同じです。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SZIn8UM6PSB4","outputId":"591b3194-fd25-4c22-cee2-7b934ac3874d"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34mGoing to initiate execution of operator LoadPILOperator\u001b[39m\n","\u001b[32mExecuting operator LoadPILOperator \u001b[33m(Process ID: 18328, Operator ID: 70e92517-e6ad-4d0a-aaff-2141c672d587)\u001b[39m\n","\u001b[34mDone performing execution of operator LoadPILOperator\n","\u001b[39m\n","\u001b[34mGoing to initiate execution of operator MedNISTClassifierOperator\u001b[39m\n","\u001b[32mExecuting operator MedNISTClassifierOperator \u001b[33m(Process ID: 18328, Operator ID: a9a7fc21-b180-4981-b775-ea8736e805a2)\u001b[39m\n","Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448272031/work/c10/core/TensorImpl.h:1156.)\n","AbdomenCT\n","\u001b[34mDone performing execution of operator MedNISTClassifierOperator\n","\u001b[39m\n"]}],"source":["!monai-deploy exec mednist_classifier_monaideploy.py -i {test_input_path} -o output -m classifier.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vNfXozk2PSB4","outputId":"8445dafb-ae76-483f-ef5e-cb70aa80512e"},"outputs":[{"name":"stdout","output_type":"stream","text":["\"AbdomenCT\""]}],"source":["!cat output/output.json"]},{"cell_type":"markdown","metadata":{"id":"YX8klpziPSB4"},"source":["### アプリのパッケージ化"]},{"cell_type":"markdown","metadata":{"id":"UcBrS_zGPSB4"},"source":["<a href=\"https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/developing_with_sdk/packaging_app.html\">MONAI Application Packager</a>でアプリをパッケージ化しよう。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HX-IkbkIPSB5","outputId":"c0464285-3842-47ef-9d4c-c9477cf8a76a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Building MONAI Application Package... Done\n","[2021-09-20 17:01:24,898] [INFO] (app_packager) - Successfully built mednist_app:latest\n"]}],"source":["!monai-deploy package mednist_classifier_monaideploy.py --tag mednist_app:latest --model classifier.zip  # -l DEBUG"]},{"cell_type":"markdown","metadata":{"id":"036hmxYyPSB5"},"source":[":::{note}\n","MONAIアプリケーションパッケージ（Dockerイメージ）のビルドには、時間がかかることがあります。進捗を確認したい場合は、`-l DEBUG`オプションを使用します。\n","\n",":::\n","\n","Docker イメージが作成されていることが確認できます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rDaX54sxPSB5","outputId":"cd9f89e2-369e-4e5c-fe7a-e24ad44ceff0"},"outputs":[{"name":"stdout","output_type":"stream","text":["mednist_app                                                             latest                                   8c78cc6e0966        3 seconds ago       15.3GB\n"]}],"source":["!docker image ls | grep mednist_app"]},{"cell_type":"markdown","metadata":{"id":"vd_XQ6SQPSB5"},"source":["### パッケージ化されたアプリをローカルで実行する\n","\n","パッケージ化されたアプリは、<a href=\"https://docs.monai.io/projects/monai-deploy-app-sdk/en/latest/developing_with_sdk/executing_packaged_app_locally.html\">MONAI Application Runner</a>を使ってローカルに実行することができます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LEWVrPTKPSB5","outputId":"2226501f-4c54-490a-b8ce-0b59b3f28362"},"outputs":[{"name":"stdout","output_type":"stream","text":["Checking dependencies...\n","--> Verifying if \"docker\" is installed...\n","\n","--> Verifying if \"mednist_app:latest\" is available...\n","\n","Checking for MAP \"mednist_app:latest\" locally\n","\"mednist_app:latest\" found.\n","\n","Reading MONAI App Package manifest...\n"," > export '/var/run/monai/export/' detected\n","--> Verifying if \"nvidia-docker\" is installed...\n","\n","\u001b[34mGoing to initiate execution of operator LoadPILOperator\u001b[39m\n","\u001b[32mExecuting operator LoadPILOperator \u001b[33m(Process ID: 1, Operator ID: 7bb4824c-ebc7-4801-a0c3-1c5525b132cf)\u001b[39m\n","\u001b[34mDone performing execution of operator LoadPILOperator\n","\u001b[39m\n","\u001b[34mGoing to initiate execution of operator MedNISTClassifierOperator\u001b[39m\n","\u001b[32mExecuting operator MedNISTClassifierOperator \u001b[33m(Process ID: 1, Operator ID: d27f4a05-e557-49c3-8adf-08f83a860d14)\u001b[39m\n","AbdomenCT\n","\u001b[34mDone performing execution of operator MedNISTClassifierOperator\n","\u001b[39m\n"]}],"source":["# テスト用入力ファイルを'input'フォルダにコピーします。\n","!mkdir -p input && rm -rf input/*\n","!cp {test_input_path} input/\n","\n","# アプリを起動する\n","!monai-deploy run mednist_app:latest input output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q4ikYrSPPSB6","outputId":"413c7c05-859c-411e-b994-0aaaf3f53f0d"},"outputs":[{"name":"stdout","output_type":"stream","text":["\"AbdomenCT\""]}],"source":["!cat output/output.json"]},{"cell_type":"markdown","metadata":{"id":"9XWyr0QaPSB6"},"source":["**Note**: 演習が終了したら、以下のスクリプトを実行してください。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J72UOehYPSB6"},"outputs":[],"source":["# Remove data files which is in the temporary folder\n","if directory is None:\n","    shutil.rmtree(root_dir)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}